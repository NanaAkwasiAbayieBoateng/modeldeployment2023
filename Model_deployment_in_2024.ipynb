{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary\n",
    "Machine learning deployment is the process of integrating a trained machine learning model into a production environment, enabling it to generate predictions and insights from real-world data. This crucial step transforms theoretical models into practical applications, allowing organizations to leverage the predictive capabilities of machine learning to drive decision-making and enhance operational efficiency. As industries increasingly adopt machine learning technologies, understanding the deployment process has become essential for maximizing the value derived from these advanced algorithms.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " The deployment process encompasses several key stages, including model selection and training, evaluation, infrastructure setup, integration, and ongoing monitoring and improvement. Each of these phases plays a critical role in ensuring that the deployed model functions effectively in its intended context. Notably, challenges such as scalability, monitoring, version control, and security must be navigated to maintain the accuracy and reliability of machine learning applications over time.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[4]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Organizations are also encouraged to adhere to best practices, including documentation, error resolution, and continuous training, to ensure sustainable deployment outcomes.[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " The topic of machine learning deployment has gained prominence not only due to its technical complexities but also because of the ethical considerations associated with its use. Issues such as algorithmic bias, data privacy, and the environmental impact of model training raise significant concerns that organizations must address to foster trust and accountability in their AI systems.[6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[7]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Recent developments in regulatory frameworks and ethical guidelines further highlight the importance of responsible deployment practices in the rapidly evolving landscape of machine learning technologies.[8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[9]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " In summary, effective machine learning deployment is a multi-faceted process that requires careful planning, execution, and continuous evaluation. As organizations navigate the complexities of deploying machine learning models, they must balance technological innovation with ethical responsibility to maximize the benefits of their AI initiatives.[10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[11]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Process of Machine Learning Deployment\n",
    "The process of machine learning deployment involves several key steps that transform a trained model into a functional application in a real-world environment. This process is critical for organizations to leverage the predictive power of machine learning models effectively.\n",
    "\n",
    "Steps in the Deployment Process\n",
    "1. Model Selection and Training\n",
    "The first step in deployment is selecting an appropriate machine learning model tailored to the specific problem at hand. This involves evaluating the characteristics of the data and the desired outcomes, which may pertain to classification, regression, or clustering tasks. After selecting a model, it is trained using preprocessed data, where the model learns patterns and relationships to make accurate predictions[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". During this phase, the data is typically split into a training set and a validation set to facilitate effective learning and performance evaluation[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "2. Model Evaluation\n",
    "Once the model is trained, it must be evaluated using a separate validation or test dataset. This step assesses the model's performance on unseen data to ensure it generalizes well and maintains accuracy in real-world applications. Various evaluation metrics, such as accuracy, precision, recall, and mean squared error, are employed to gauge the model's effectiveness[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". If the model does not meet the desired performance thresholds, it may require further refinement, which could include adjusting the model's architecture or hyperparameters[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "3. Infrastructure and Environment Setup\n",
    "Deployment necessitates the establishment of the appropriate infrastructure and environment to support the model's operation. This may involve configuring servers, utilizing cloud platforms, or setting up other computational resources to handle the model's processing requirements. It is vital that this infrastructure is scalable to accommodate growing demands and provide reliable performance[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "4. Integration\n",
    "The model must then be integrated into existing systems or applications, which is a critical aspect of the deployment process. This integration could involve embedding the model within a web application, interfacing it with an API, or incorporating it into current software systems. A well-planned integration strategy ensures seamless communication between the model and other components of the infrastructure, allowing for efficient operation[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "5. Continuous Evaluation and Improvement\n",
    "Deployment is not a one-time process; it requires ongoing evaluation and improvement. Organizations should regularly assess the deployed model's performance and impact, collecting feedback from end-users to identify areas for enhancement. This continuous improvement cycle ensures that the models remain effective and aligned with evolving business needs, adapting to new data inputs and changing environments[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". By following these steps, organizations can successfully deploy machine learning models that not only meet their operational requirements but also provide substantial business value through data-driven insights[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Definition of Deployment\n",
    "In the context of machine learning, deployment refers to making a trained model accessible for use in production environments. This integration allows the model to receive input data, make predictions, and generate actionable insights in real time[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Tools and Frameworks for Deployment\n",
    "The deployment of machine learning models is supported by a variety of tools and frameworks that streamline the process, enhance scalability, and ensure reliability. These tools cater to different deployment strategies, including containerization, orchestration, and API integration.\n",
    "\n",
    "Seldon Core\n",
    "Seldon Core is an open-source framework that accelerates the deployment of machine learning models while simplifying the process.[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " It supports models created with any open-source machine learning framework and is built on Kubernetes, allowing for the use of advanced Kubernetes features. This includes managing model graphs and scaling resources as necessary. Seldon also facilitates connections to continuous integration and deployment (CI/CD) solutions, and provides alerts for issues in production, making it suitable for both on-premises and cloud deployments.\n",
    "\n",
    "AWS SageMaker\n",
    "Amazon SageMaker is a comprehensive service that enables developers and data scientists to build, train, and deploy machine learning models efficiently.[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " It includes an integrated Jupyter notebook for data analysis, eliminating server management. SageMaker offers various modules that can be used independently or together, providing optimized machine learning methods for large datasets.\n",
    "\n",
    "TensorFlow Serving\n",
    "TensorFlow Serving is designed for high-performance serving of machine learning models, allowing trained models to be deployed as REST API endpoints.[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " This flexibility enables real-time predictions and is capable of handling various data types. Its architecture supports multiple users and efficiently manages high request volumes with load balancing. TensorFlow Serving is widely utilized by major companies, including Google, as a central solution for model serving.\n",
    "\n",
    "Containerization and Deployment Orchestration\n",
    "Containerization technologies like Docker play a crucial role in the deployment of machine learning models. They package models, dependencies, and configurations into portable containers, ensuring consistent deployment across different environments.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Kubernetes, as a container orchestration tool, automates the management of these containers, providing features for scaling, load balancing, and fault tolerance.\n",
    "\n",
    "Deployment Strategies\n",
    "Different deployment methods cater to varying needs:\n",
    "\n",
    "Web API Deployment: Deploys models as web services accessed via APIs, facilitating real-time predictions.\n",
    "Cloud-based Deployment: Models are hosted on cloud platforms, allowing for dynamic scaling and cost efficiency.\n",
    "Container Deployment: Models are packaged in containers and orchestrated with Kubernetes, integrating seamlessly with existing infrastructures.\n",
    "Offline Deployment: Models run on batches of data, suitable for applications that can handle periodic updates.[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Best Practices for Deployment\n",
    "Successful deployment of machine learning models involves several best practices that ensure models are reliable, maintainable, and scalable in real-world applications.\n",
    "\n",
    "Version Control\n",
    "Version control is essential for managing machine learning models, code, and configurations. By implementing systems like Git, organizations can track changes, document enhancements, and manage different versions of models throughout their lifecycle.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " This practice allows for easier collaboration among team members and simplifies the process of rolling back to previous versions if needed.\n",
    "\n",
    "Documentation\n",
    "Proper documentation is crucial during the deployment process. It should encompass all steps taken, decisions made, and the reasoning behind those decisions. This documentation should include details about the model pipeline, data preprocessing, infrastructure specifics, performance metrics, and unique considerations specific to the deployment.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Comprehensive documentation facilitates easier reproduction of the deployment and aids future team members or stakeholders in understanding the process.\n",
    "\n",
    "Monitoring and Performance Evaluation\n",
    "Monitoring deployed models is vital for tracking key performance metrics and assessing their effectiveness. This includes evaluating inputs, outputs, and intermediate data throughout the model pipeline. Organizations should define specific performance metrics based on the task at hand, such as accuracy for classification tasks or mean squared error for regression tasks.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Regular monitoring helps identify anomalies and areas for improvement, ensuring that models remain aligned with business objectives.\n",
    "\n",
    "Continuous Integration and Delivery (CI/CD)\n",
    "Implementing CI/CD pipelines automates the integration, testing, and deployment processes for machine learning models. Automation increases efficiency and reduces the time from development to deployment by ensuring models are regularly updated and deployed without manual intervention.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " CI/CD practices support a more agile deployment process, enabling quicker responses to changes in requirements or data.\n",
    "\n",
    "Containerization and Orchestration\n",
    "Containerization is a popular method for deploying machine learning models, allowing developers to package models with their dependencies into portable containers.[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Tools like Docker and Kubernetes facilitate consistent deployment across different environments and support efficient scaling and management of containers. This orchestration ensures high availability and reliability, especially during fluctuating workloads.\n",
    "\n",
    "Ongoing Training and Adaptation\n",
    "To maintain accuracy and relevance, machine learning models must be periodically retrained with new data. This ongoing training process may involve incorporating new labeled data or leveraging transfer learning techniques to adapt to changing data patterns.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Regular updates help ensure models continue to perform effectively as the environment evolves.\n",
    "\n",
    "Error Resolution and Maintenance\n",
    "Timely diagnosis and resolution of errors are critical for maintaining deployed models. Organizations should implement logging and error tracking mechanisms to quickly identify and address issues related to data, code, or infrastructure.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Establishing a robust process for error resolution ensures minimal downtime and maintains user trust in the deployed models. By following these best practices, organizations can enhance the effectiveness and sustainability of their machine learning deployments, ultimately leading to improved performance and user satisfaction.\n",
    "\n",
    "Challenges in Machine Learning Deployment\n",
    "Machine learning deployment presents several challenges that organizations must navigate to ensure the successful integration of their models into real-world applications. These challenges encompass various aspects, including scalability, monitoring, maintenance, and security.\n",
    "\n",
    "Monitoring and Maintenance\n",
    "After deployment, continuous monitoring and maintenance are essential to ensure ongoing model effectiveness. This involves tracking key performance metrics, monitoring input data quality, and setting up alerts to detect anomalies or performance degradation[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Without robust monitoring mechanisms, organizations risk overlooking issues that could lead to decreased accuracy or reliability of their machine learning models. Regular maintenance procedures, including model updates and retraining on new data, are also vital to address any changes in data patterns or user requirements[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Scalability Issues\n",
    "One of the primary challenges in machine learning deployment is scalability. As the volume of data and user demands increases, it is crucial for deployed models to handle growing workloads without compromising performance. Organizations must carefully consider their deployment infrastructure, including computational resources, storage capacity, and network bandwidth, to accommodate these demands effectively[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Cloud-based solutions such as AWS, Google Cloud, and Azure offer scalable infrastructures that can automatically adjust resources based on real-time demand, thus enhancing performance during peak loads[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Version Control\n",
    "Effective version control is another critical challenge in machine learning deployment. Organizations must manage different versions of models and associated code throughout the deployment process. This includes saving snapshots of models at various stages of development and maintaining records of modifications[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Proper version control ensures reproducibility and facilitates performance evaluation, allowing teams to roll back changes if necessary and compare model versions against specific features or datasets[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Security and Privacy Concerns\n",
    "Security and privacy are paramount when deploying machine learning models, especially when handling sensitive data. Organizations must implement measures to protect against unauthorized access and data breaches, which could have severe implications for both privacy and compliance with regulations like GDPR, CCPA, and HIPAA[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Techniques such as data anonymization and encryption play a crucial role in safeguarding sensitive information during the deployment process[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Additional Considerations\n",
    "Deploying machine learning models is inherently complex, requiring careful planning and execution to address these challenges. Organizations must consider various factors, such as infrastructure scalability, monitoring systems, maintenance routines, version control, and security protocols, to ensure that their models remain effective and reliable over time[2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". By tackling these challenges head-on, organizations can leverage the full potential of their machine learning models in real-world applications.\n",
    "\n",
    "Best Practices for Deployment\n",
    "Successful deployment of machine learning models involves several best practices that ensure models are reliable, maintainable, and scalable in real-world applications.\n",
    "\n",
    "Version Control\n",
    "Version control is essential for managing machine learning models, code, and configurations. By implementing systems like Git, organizations can track changes, document enhancements, and manage different versions of models throughout their lifecycle.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " This practice allows for easier collaboration among team members and simplifies the process of rolling back to previous versions if needed.\n",
    "\n",
    "Documentation\n",
    "Proper documentation is crucial during the deployment process. It should encompass all steps taken, decisions made, and the reasoning behind those decisions. This documentation should include details about the model pipeline, data preprocessing, infrastructure specifics, performance metrics, and unique considerations specific to the deployment.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Comprehensive documentation facilitates easier reproduction of the deployment and aids future team members or stakeholders in understanding the process.\n",
    "\n",
    "Monitoring and Performance Evaluation\n",
    "Monitoring deployed models is vital for tracking key performance metrics and assessing their effectiveness. This includes evaluating inputs, outputs, and intermediate data throughout the model pipeline. Organizations should define specific performance metrics based on the task at hand, such as accuracy for classification tasks or mean squared error for regression tasks.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Regular monitoring helps identify anomalies and areas for improvement, ensuring that models remain aligned with business objectives.\n",
    "\n",
    "Continuous Integration and Delivery (CI/CD)\n",
    "Implementing CI/CD pipelines automates the integration, testing, and deployment processes for machine learning models. Automation increases efficiency and reduces the time from development to deployment by ensuring models are regularly updated and deployed without manual intervention.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " CI/CD practices support a more agile deployment process, enabling quicker responses to changes in requirements or data.\n",
    "\n",
    "Containerization and Orchestration\n",
    "Containerization is a popular method for deploying machine learning models, allowing developers to package models with their dependencies into portable containers.[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Tools like Docker and Kubernetes facilitate consistent deployment across different environments and support efficient scaling and management of containers. This orchestration ensures high availability and reliability, especially during fluctuating workloads.\n",
    "\n",
    "Ongoing Training and Adaptation\n",
    "To maintain accuracy and relevance, machine learning models must be periodically retrained with new data. This ongoing training process may involve incorporating new labeled data or leveraging transfer learning techniques to adapt to changing data patterns.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Regular updates help ensure models continue to perform effectively as the environment evolves.\n",
    "\n",
    "Error Resolution and Maintenance\n",
    "Timely diagnosis and resolution of errors are critical for maintaining deployed models. Organizations should implement logging and error tracking mechanisms to quickly identify and address issues related to data, code, or infrastructure.[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " Establishing a robust process for error resolution ensures minimal downtime and maintains user trust in the deployed models. By following these best practices, organizations can enhance the effectiveness and sustainability of their machine learning deployments, ultimately leading to improved performance and user satisfaction.\n",
    "\n",
    "Ethical Dilemmas in Deployment\n",
    "As the deployment of machine learning (ML) technologies continues to expand, it brings with it a host of ethical dilemmas that organizations must navigate. Ethical AI deployment is not just a technical challenge but a profound social imperative, necessitating a careful balance between innovation and responsibility[7]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Key Ethical Considerations\n",
    "Algorithmic Bias and Data Integrity\n",
    "One of the primary concerns in ML deployment is algorithmic bias, which occurs when AI systems are trained on unrepresentative or incomplete datasets. Historical biases embedded in training data can perpetuate inequalities, leading to biased outcomes in critical areas such as hiring, criminal justice, and healthcare[8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Notably, the experiences of researchers like Dr. Joy Buolamwini illustrate how insufficient diversity in datasets can skew AI performance, particularly affecting marginalized groups[8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Organizations must prioritize data integrity and ensure that the datasets used in training are representative and free from historical biases.\n",
    "\n",
    "Environmental Impact\n",
    "The environmental implications of ML model training are increasingly coming under scrutiny. Training large language models, for instance, consumes significant energy resources, equivalent to the carbon footprint of multiple long-haul flights[8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". As the demand for AI continues to rise, organizations are urged to consider the environmental impact of their technologies and strive for sustainable practices in their deployment strategies.\n",
    "\n",
    "Transparency and Accountability\n",
    "Transparency is critical in building trust in AI systems. Stakeholders benefit from clear communication about how AI models make decisions, which is especially crucial in sectors like finance and healthcare where decisions can have far-reaching consequences[9]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Providing detailed reports on AI performance and maintaining open channels for dialogue can help foster a culture of accountability. This transparency also extends to adhering to regulatory standards, such as GDPR, ensuring that data privacy and ethical considerations are integral to AI operations[9]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Ethical Decision-Making in Autonomous Systems\n",
    "The deployment of autonomous systems, such as self-driving cars, raises unique ethical challenges. These systems must be programmed to make split-second decisions in scenarios where harm is unavoidable, forcing developers to confront difficult moral questions regarding the prioritization of lives[9]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". The development of ethical frameworks for such decision-making processes is vital to ensure that the technology aligns with societal values and ethical principles.\n",
    "\n",
    "Privacy and Data Protection\n",
    "With the increasing use of personal data in training ML models, privacy concerns are paramount. Organizations must implement robust data protection measures, such as data anonymization and secure storage protocols, to safeguard individual privacy[9]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Adhering to privacy regulations not only protects users but also enhances trust in AI technologies.\n",
    "\n",
    "Case Studies\n",
    "The exploration of machine learning deployment is significantly enhanced by case studies that highlight both the successes and challenges encountered in real-world applications. These case studies serve as valuable resources for understanding how machine learning models are implemented and the ethical considerations that arise during deployment.\n",
    "\n",
    "Princeton Dialogues on AI and Ethics\n",
    "One notable collection of case studies is the Princeton Dialogues on AI and Ethics, which includes a series of fictional case studies designed to prompt reflection and discussion on the ethical dilemmas at the intersection of AI and societal impacts. These studies, developed through an interdisciplinary workshop series at Princeton University, are underpinned by five guiding principles: empirical foundations, broad accessibility, interactiveness, multiple viewpoints, and depth over brevity[10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[11]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Example Case Studies\n",
    "Automated Healthcare App: This case study examines issues of legitimacy, paternalism, transparency, censorship, and inequality[10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". It reflects on how AI can influence healthcare delivery and the ethical implications of automating patient interactions.\n",
    "Dynamic Sound Identification: Focused on rights, representational harms, neutrality, and downstream responsibility, this study illustrates the complexities involved in sound recognition technologies and their societal ramifications[10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "Optimizing Schools: This case addresses privacy, autonomy, consequentialism, and rhetoric, exploring the ethical dimensions of using AI in educational settings to optimize learning experiences and administrative processes[10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "Law Enforcement Chatbots: Highlighting the ethical concerns of automation, research ethics, and sovereignty, this case study delves into the use of AI chatbots within law enforcement agencies and the implications for justice and civil rights[10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "Hiring By Machine: This case emphasizes the ethical challenges in employing AI for hiring processes, including issues of bias and fairness, and the responsibility of organizations to ensure equitable outcomes[10]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "Real-World Applications and Ethical Considerations\n",
    "The importance of ethical considerations in machine learning deployment is underscored by practical examples, such as the unintentional biases that can arise from flawed data collection methods. For instance, a facial recognition model trained predominantly on data from a specific demographic may perform poorly on individuals from different backgrounds, highlighting the critical need for diverse and representative datasets in the training phase[12]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Framework for Responsible Deployment\n",
    "To ensure responsible deployment, organizations are encouraged to implement frameworks that include error analysis, bias mitigation strategies, assigned responsibility for monitoring models, and transparent reporting practices[12]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Establishing a feedback loop for continuous improvement based on user behavior and model performance is also essential, as it allows organizations to adapt and enhance their models post-deployment[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". By learning from these case studies and applying best practices in ethical oversight, organizations can navigate the complexities of machine learning deployment while fostering trust and accountability within the AI ecosystem.\n",
    "\n",
    "Frameworks and Guidelines for Ethical Deployment\n",
    "Importance of Ethical Considerations in Machine Learning\n",
    "The deployment of machine learning (ML) models necessitates careful attention to ethical considerations, as unethical practices can lead to biased outcomes, which in turn can damage an organization's reputation and disrupt projects[13]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Ethical frameworks play a crucial role in guiding the responsible development and implementation of AI technologies. This is particularly vital given the potential for AI to reflect and amplify existing societal biases found in training data[14]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[15]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Established Guidelines and Frameworks\n",
    "Various organizations and research communities are actively working on establishing ethical guidelines for AI and ML deployment. For example, the Organisation for Economic Cooperation and Development (OECD) has issued guidelines that promote human-centric values, inclusivity, and sustainability in AI[16]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". Moreover, initiatives by organizations like OpenAI and the IEEE are focused on promoting responsible AI development by encouraging researchers to consider the social and ethical implications of their work[16]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[17]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Key Principles of Responsible AI\n",
    "Responsible AI deployment is anchored in several key principles that organizations must adhere to in order to ensure ethical compliance:\n",
    "\n",
    "Fairness and Bias Mitigation: AI systems should be designed to avoid discrimination against any group. This requires identifying biases in training data and implementing techniques to mitigate them, thus ensuring fairness in decisions made by AI systems[18]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[19]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "Transparency: Organizations must maintain transparency in how AI systems operate, making it easier for users to understand decision-making processes[20]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "Accountability: It is essential to establish clear lines of accountability for AI outcomes. When a machine learning model results in harm or error, the organization behind it must take responsibility and take corrective action[14]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[16]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "Diverse Perspectives: Including diverse perspectives in the design and testing phases can help minimize harmful biases and improve the ethical integrity of the AI system[19]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[20]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "Regulatory and Legislative Initiatives\n",
    "As the use of AI and ML technologies expands, governments worldwide are starting to introduce legislation aimed at regulating these systems. The U.S. has initiated the Algorithmic Accountability Act, which focuses on addressing biases and ensuring ethical development in AI[16]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". These legal frameworks are essential for ensuring that organizations are held to ethical standards during the deployment of machine learning solutions.\n",
    "\n",
    "Moving Forward with Responsible AI\n",
    "To effectively address potential biases and ethical challenges in AI deployment, organizations should establish internal review boards, conduct regular bias assessments, and provide training on AI ethics for their employees[17]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[18]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". These practices will help ensure that AI systems not only enhance operational efficiency but also align with societal values and ethical standards, fostering a more responsible approach to machine learning deployment.\n",
    "\n",
    "Future Trends in Machine Learning Deployment\n",
    "As machine learning deployment continues to evolve, several trends are shaping its future, enhancing how organizations utilize and implement machine learning models in real-world applications. These trends focus on improving scalability, efficiency, and responsiveness to emerging technologies and market demands.\n",
    "\n",
    "Serverless Architectures\n",
    "One significant trend is the increasing adoption of serverless computing frameworks, such as AWS Lambda, Google Cloud Functions, and Azure Functions. These platforms enable businesses to run code in response to events without the need for managing servers, allowing for greater scalability and cost-efficiency in deployment processes. By leveraging serverless architectures, organizations can facilitate real-time predictions and streamline their deployment workflows, thus optimizing resource utilization and operational expenses[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Edge Computing\n",
    "Edge computing is gaining traction as a deployment strategy that involves executing machine learning models closer to the data source, such as on IoT devices or edge servers. This approach significantly reduces latency and bandwidth usage, enabling real-time predictions and decision-making, especially in environments with limited connectivity. Industries such as healthcare, manufacturing, and autonomous systems are particularly benefitting from edge deployment, which allows for immediate responses critical to operations[5]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[21]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "MLOps Integration\n",
    "The integration of MLOps (Machine Learning Operations) practices into deployment processes is becoming essential for organizations seeking to leverage machine learning effectively. MLOps encompasses the automation of workflows related to data processing, model training, deployment, and monitoring. By implementing MLOps, companies can reduce manual intervention, enhance model performance, and ensure consistent deployments, thereby maximizing the return on their investment in machine learning technologies[21]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Explainable AI\n",
    "As machine learning systems become more integrated into decision-making processes, the need for explainability and transparency in models is increasingly critical. Organizations are adopting tools and practices that promote model interpretability, ensuring that machine learning outcomes are understandable and unbiased. This trend not only fosters stakeholder trust but also helps organizations comply with regulatory requirements, thereby promoting ethical standards in AI deployment[21]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "Enhanced Automation\n",
    "Automation is set to play a pivotal role in future deployment strategies. Automating the deployment process reduces human error, accelerates deployment timelines, and ensures consistency across different environments. By utilizing infrastructure-as-code tools and continuous integration/continuous deployment (CI/CD) pipelines, businesses can create reliable and scalable deployment environments, facilitating easier updates and modifications to their models[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[6]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    ". These emerging trends indicate that machine learning deployment is transitioning towards more agile, efficient, and responsible practices, allowing organizations to harness the full potential of their data-driven insights and innovations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Deployment in 2024\n",
    "\n",
    "\n",
    "### Hugginface face Space\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?app=desktop&v=ZBXNyOPv6mM\n",
    "\n",
    "https://www.youtube.com/watch?v=I9eK7idNCGw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streamlit Community Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deployment with mlflow,github actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "- Loan_id A unique loan number assigned to each loan customers\n",
    "\n",
    "- Loan_status Whether a loan is paid off, in collection, new customer yet to payoff, or paid off after the collection efforts\n",
    "\n",
    "- Principal Basic principal loan amount at the origination\n",
    "\n",
    "- terms Can be weekly (7 days), biweekly, and monthly payoff schedule\n",
    "\n",
    "- Effective_date When the loan got originated and took effects\n",
    "\n",
    "- Due_date Since it’s one-time payoff schedule, each loan has one single due date\n",
    "\n",
    "- Paidoff_time The actual time a customer pays off the loan\n",
    "\n",
    "- Pastdue_days How many days a loan has been past due\n",
    "\n",
    "- Age, education, gender A customer’s basic demographic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>Principal</th>\n",
       "      <th>terms</th>\n",
       "      <th>effective_date</th>\n",
       "      <th>due_date</th>\n",
       "      <th>paid_off_time</th>\n",
       "      <th>past_due_days</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xqd20166231</td>\n",
       "      <td>PAIDOFF</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>9/8/2016</td>\n",
       "      <td>10/7/2016</td>\n",
       "      <td>9/14/2016 19:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45</td>\n",
       "      <td>High School or Below</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xqd20168902</td>\n",
       "      <td>PAIDOFF</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>9/8/2016</td>\n",
       "      <td>10/7/2016</td>\n",
       "      <td>10/7/2016 9:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>Bechalor</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xqd20160003</td>\n",
       "      <td>PAIDOFF</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>9/8/2016</td>\n",
       "      <td>10/7/2016</td>\n",
       "      <td>9/25/2016 16:58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>Bechalor</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xqd20160004</td>\n",
       "      <td>PAIDOFF</td>\n",
       "      <td>1000</td>\n",
       "      <td>15</td>\n",
       "      <td>9/8/2016</td>\n",
       "      <td>9/22/2016</td>\n",
       "      <td>9/22/2016 20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27</td>\n",
       "      <td>college</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xqd20160005</td>\n",
       "      <td>PAIDOFF</td>\n",
       "      <td>1000</td>\n",
       "      <td>30</td>\n",
       "      <td>9/9/2016</td>\n",
       "      <td>10/8/2016</td>\n",
       "      <td>9/23/2016 21:36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>college</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loan_ID loan_status  Principal  terms effective_date   due_date  \\\n",
       "0  xqd20166231     PAIDOFF       1000     30       9/8/2016  10/7/2016   \n",
       "1  xqd20168902     PAIDOFF       1000     30       9/8/2016  10/7/2016   \n",
       "2  xqd20160003     PAIDOFF       1000     30       9/8/2016  10/7/2016   \n",
       "3  xqd20160004     PAIDOFF       1000     15       9/8/2016  9/22/2016   \n",
       "4  xqd20160005     PAIDOFF       1000     30       9/9/2016  10/8/2016   \n",
       "\n",
       "     paid_off_time  past_due_days  age             education  Gender  \n",
       "0  9/14/2016 19:31            NaN   45  High School or Below    male  \n",
       "1   10/7/2016 9:00            NaN   50              Bechalor  female  \n",
       "2  9/25/2016 16:58            NaN   33              Bechalor  female  \n",
       "3  9/22/2016 20:00            NaN   27               college    male  \n",
       "4  9/23/2016 21:36            NaN   28               college  female  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder,LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "dir_loc = \"C:/Users/nboateng/OneDrive - Nice Systems Ltd/Documents/Deployment_Dashboards/modeldeployment2024/\"\n",
    "#data location on kaggle https://www.kaggle.com/datasets/zhijinzhai/loandata\n",
    "#df = pd.read_csv(\"C:/Users/nboateng/OneDrive - Nice Systems Ltd/Documents/Deployment_Dashboards/Model_Deployment_2024/Loan payments data.csv\", parse_dates = ['effective_date', 'paid_off_time','due_date'])\n",
    "df = pd.read_csv( dir_loc + \"Loan payments data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   Principal  500 non-null    float64\n",
      " 1   terms      500 non-null    float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def month_date(df):\n",
    "    #d =  df.apply(lambda x:x.str.slice(5, 7)).astype(float)\n",
    "    d =  df.apply(lambda x: pd.to_datetime(x).dt.month)\n",
    "    return d\n",
    "\n",
    "\n",
    "def quarter_date(df):\n",
    "    d = df.apply(lambda x: pd.to_datetime(x).dt.quarter)\n",
    "    return d\n",
    "\n",
    "\n",
    "def cast_float(df):\n",
    "    #d = df.apply(lambda x: pd.DataFrame(x).astype(float))\n",
    "    return df.astype(float)\n",
    "\n",
    "def to_object(x):\n",
    "  return pd.DataFrame(x).astype(object)\n",
    "\n",
    "def to_numeric(x):\n",
    "  return pd.DataFrame(x).astype(float)\n",
    "\n",
    "fun_tr = FunctionTransformer(to_object)\n",
    "\n",
    "num_tr = FunctionTransformer(to_numeric)\n",
    "\n",
    "get_month_date = FunctionTransformer(month_date)    \n",
    " \n",
    "get_quarter_date = FunctionTransformer(quarter_date)\n",
    "\n",
    "cast_col_float = FunctionTransformer(to_numeric)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    \n",
    "     (get_month_date,['due_date','paid_off_time']),\n",
    "    (get_quarter_date,['effective_date'])\n",
    ")\n",
    "\n",
    "\n",
    "cast_num = make_column_transformer(\n",
    "    \n",
    "     (cast_float,['Principal','terms','past_due_days'\t,'age'])\n",
    "   \n",
    ")\n",
    "\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "ct.fit_transform(df)\n",
    "\n",
    "#cast_num.fit_transform(df)\n",
    "\n",
    "#y = fun_tr.fit_transform(pd.DataFrame({'a':[1,2,3]}))\n",
    "#y = num_tr.fit_transform(pd.DataFrame({'a':[1,2,3]}))\n",
    "y = num_tr.fit_transform(df[['Principal','terms']])\n",
    "y.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder,StandardScaler,OneHotEncoder\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "\n",
    "\n",
    "# Features and target variable\n",
    "X = df.drop(columns=['Loan_ID',\t'loan_status'])\n",
    "y = df['loan_status']\n",
    "\n",
    "# Columns to be scaled\n",
    "numeric_features = ['Principal','terms','past_due_days'\t,'age']\n",
    "\n",
    "# Column to be binned and one-hot encoded\n",
    "categorical_features = ['education',\t'Gender']\n",
    "\n",
    "# Create transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='median')),\n",
    "    ('imputer', SimpleImputer(fill_value= -9999, strategy='constant'))\n",
    "    #('scaler', MinMaxScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('bin', KBinsDiscretizer(n_bins=6, encode='ordinal', strategy='quantile')),\n",
    "    #('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "   ('encoder', OrdinalEncoder(handle_unknown= 'use_encoded_value', unknown_value=-1)),\n",
    "])\n",
    "\n",
    "# Combine all transformers into a preprocessor using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create and evaluate the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [17:32:10] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numeric_transform&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 fill_value=-9999,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;cast_float&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;function to_numeric at 0x000001DC372C5120&gt;))]),\n",
       "                                                  [&#x27;Principal&#x27;, &#x27;terms&#x27;,\n",
       "                                                   &#x27;past_due_days&#x27;, &#x27;age&#x27;]),\n",
       "                                                 (&#x27;date_eng_feat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;da...\n",
       "                               feature_types=None, gamma=0.05, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=1,\n",
       "                               max_depth=5, max_leaves=None, min_child_weight=2,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
       "                               num_class=3, num_parallel_tree=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;numeric_transform&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 fill_value=-9999,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;cast_float&#x27;,\n",
       "                                                                   FunctionTransformer(func=&lt;function to_numeric at 0x000001DC372C5120&gt;))]),\n",
       "                                                  [&#x27;Principal&#x27;, &#x27;terms&#x27;,\n",
       "                                                   &#x27;past_due_days&#x27;, &#x27;age&#x27;]),\n",
       "                                                 (&#x27;date_eng_feat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;da...\n",
       "                               feature_types=None, gamma=0.05, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=1,\n",
       "                               max_depth=5, max_leaves=None, min_child_weight=2,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
       "                               num_class=3, num_parallel_tree=None, ...))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;preprocessor: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for preprocessor: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;numeric_transform&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(add_indicator=True,\n",
       "                                                                fill_value=-9999,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;cast_float&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function to_numeric at 0x000001DC372C5120&gt;))]),\n",
       "                                 [&#x27;Principal&#x27;, &#x27;terms&#x27;, &#x27;past_due_days&#x27;,\n",
       "                                  &#x27;age&#x27;]),\n",
       "                                (&#x27;date_eng_feat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;date&#x27;,\n",
       "                                                  FunctionTransformer(func=&lt;function quarter_date at 0x000001DC372C6CA0&gt;))]),\n",
       "                                 [&#x27;due_date&#x27;, &#x27;paid_off_time&#x27;,\n",
       "                                  &#x27;effective_date&#x27;]),\n",
       "                                (&#x27;categorical_encoding&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;ordinal&#x27;,\n",
       "                                                  OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;,\n",
       "                                                                 unknown_value=-1)),\n",
       "                                                 (&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;))]),\n",
       "                                 [&#x27;education&#x27;, &#x27;Gender&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">numeric_transform</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;Principal&#x27;, &#x27;terms&#x27;, &#x27;past_due_days&#x27;, &#x27;age&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(add_indicator=True, fill_value=-9999, strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function to_numeric at 0x000001DC372C5120&gt;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">date_eng_feat</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;due_date&#x27;, &#x27;paid_off_time&#x27;, &#x27;effective_date&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-40\" type=\"checkbox\" ><label for=\"sk-estimator-id-40\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;FunctionTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.FunctionTransformer.html\">?<span>Documentation for FunctionTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>FunctionTransformer(func=&lt;function quarter_date at 0x000001DC372C6CA0&gt;)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-41\" type=\"checkbox\" ><label for=\"sk-estimator-id-41\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">categorical_encoding</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;education&#x27;, &#x27;Gender&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" ><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OrdinalEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder(handle_unknown=&#x27;use_encoded_value&#x27;, unknown_value=-1)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">XGBClassifier</label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False,\n",
       "              eval_metric=&lt;function auc at 0x000001DC354962A0&gt;,\n",
       "              feature_types=None, gamma=0.05, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=1, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=2, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=50,\n",
       "              n_jobs=-1, num_class=3, num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('numeric_transform',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=True,\n",
       "                                                                                 fill_value=-9999,\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('cast_float',\n",
       "                                                                   FunctionTransformer(func=<function to_numeric at 0x000001DC372C5120>))]),\n",
       "                                                  ['Principal', 'terms',\n",
       "                                                   'past_due_days', 'age']),\n",
       "                                                 ('date_eng_feat',\n",
       "                                                  Pipeline(steps=[('da...\n",
       "                               feature_types=None, gamma=0.05, grow_policy=None,\n",
       "                               importance_type=None,\n",
       "                               interaction_constraints=None, learning_rate=0.1,\n",
       "                               max_bin=None, max_cat_threshold=None,\n",
       "                               max_cat_to_onehot=None, max_delta_step=1,\n",
       "                               max_depth=5, max_leaves=None, min_child_weight=2,\n",
       "                               missing=nan, monotone_constraints=None,\n",
       "                               multi_strategy=None, n_estimators=50, n_jobs=-1,\n",
       "                               num_class=3, num_parallel_tree=None, ...))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_selector\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder,StandardScaler,OneHotEncoder\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "from sklearn import *\n",
    "from sklearn.metrics import roc_curve, roc_auc_score,balanced_accuracy_score,f1_score,confusion_matrix\n",
    "\n",
    "# Columns to be scaled\n",
    "numeric_features = ['Principal','terms','past_due_days'\t,'age']\n",
    "\n",
    "# Column to be binned and one-hot encoded\n",
    "categorical_features = ['education',\t'Gender']\n",
    "\n",
    "date_cols =  ['due_date','paid_off_time','effective_date']\n",
    "\n",
    "\n",
    "\n",
    "target_column  =  ['loan_status']\n",
    "\n",
    "feat_list  =  numeric_features  +  categorical_features +   date_cols  \n",
    "\n",
    "\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('encoding',LabelEncoder()),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown= 'use_encoded_value', unknown_value=-1)),\n",
    "     #('label_encoding',MyLabelEncoder()),\n",
    "    #('imputer', SimpleImputer(fill_value= -9999, strategy='constant'))\n",
    "     ('imputer', SimpleImputer( strategy='median')),\n",
    "    #('encoding',OrdinalEncoder(categories='auto'))\n",
    "   \n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(fill_value=-9999, strategy='constant', add_indicator=True)),\n",
    "    #('scaler', StandardScaler()) \n",
    "     ('cast_float',cast_col_float)\n",
    "    ])\n",
    "\n",
    "\n",
    "date_transformer = Pipeline(steps=[\n",
    "    ('date', get_quarter_date)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(\n",
    "             seed=1,\n",
    "              n_jobs = -1,\n",
    "              max_depth = 5,\n",
    "              learning_rate =  0.1,\n",
    "              min_child_weight= 2, \n",
    "              #min_samples_split= 0.9,\n",
    "              n_estimators= 50,\n",
    "              #eta = 0.1, \n",
    "              verbose = 1, \n",
    "              gamma=0.05,\n",
    "              #nrounds = 100\n",
    "              objective='multi:softmax', \n",
    "              num_class=3,\n",
    "              eval_metric =  metrics.auc,              #metrics.r2_score,     mean_absolute_error  #\"aucpr\",    # \"aucpr\",  #aucpr, auc\n",
    "              subsample = 0.7,\n",
    "              colsample_bytree =0.8,\n",
    "              max_delta_step=1,\n",
    "              verbosity=1,\n",
    "              tree_method='hist')\n",
    "\n",
    "# Combine all transformers into a preprocessor using ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_transform', numeric_transformer, numeric_features),\n",
    "        ('date_eng_feat',date_transformer,date_cols),\n",
    "        ('categorical_encoding', categorical_transformer, categorical_features),\n",
    "        #('label_encoder', label_transformer, target_column)\n",
    "       \n",
    "        ])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      #('dropfeature',UniqueDropper()),\n",
    "                      #('anova', SelectPercentile(chi2)),\n",
    "                      # ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))),\n",
    "                      ('classifier',xgb_classifier )])\n",
    "\n",
    "\n",
    "# Define the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[feat_list], df[target_column], test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "pipeline.fit(X=X_train, y= label_encoder.fit_transform(y_train.values.ravel()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (350, 9)\n",
      "X_test: (150, 9)\n",
      "y_train: (350, 1)\n",
      "y_test: (150, 1)\n",
      "auc :1.0\n",
      "balanced_accuracy  :1.0\n",
      "f1  :1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 2, 0, 0, 2, 2, 1, 2, 2, 1, 2, 0, 0, 1, 2, 0, 1, 1, 1,\n",
       "       2, 0, 2, 1, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2, 2, 2, 0, 2, 1, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 2,\n",
       "       1, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 1, 1, 2, 2, 1, 2, 0, 2, 2, 1,\n",
       "       0, 2, 0, 1, 0, 0, 1, 0, 2, 2, 1, 2, 2, 1, 2, 0, 0, 2, 0, 2, 0, 2,\n",
       "       2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 0, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print train and test set shape\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n",
    "# generate predictions\n",
    "y_pred = pipeline.predict(X_test)\n",
    "#y_pred_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "y_pred_prob = pipeline.predict_proba(X_test)\n",
    "y_pred_label = pipeline.predict(X_test)\n",
    "y_test_label = label_encoder.fit_transform(y_test.values.ravel())\n",
    "\n",
    "\n",
    "auc = roc_auc_score(y_test_label,y_pred_prob,multi_class='ovr')\n",
    "print('auc :{}'.format(auc))\n",
    "\n",
    "balanced_accuracy = balanced_accuracy_score(y_test_label,y_pred_label)\n",
    "print('balanced_accuracy  :{}'.format(balanced_accuracy ))\n",
    "#f1 = f1_score(y_test_label,y_pred_label,'micro')\n",
    "f1 = f1_score(y_test_label, y_pred_label, average='macro')\n",
    "print('f1  :{}'.format(f1 ))\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "joblib.dump(pipeline, dir_loc + 'pipeline.pkl')\n",
    "y_pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COLLECTION' 'PAIDOFF' 'COLLECTION' 'PAIDOFF' 'PAIDOFF' 'COLLECTION'\n",
      " 'COLLECTION' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'COLLECTION_PAIDOFF' 'PAIDOFF' 'COLLECTION' 'COLLECTION'\n",
      " 'COLLECTION_PAIDOFF' 'PAIDOFF' 'COLLECTION' 'COLLECTION_PAIDOFF'\n",
      " 'COLLECTION_PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF' 'COLLECTION'\n",
      " 'PAIDOFF' 'COLLECTION_PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'COLLECTION' 'COLLECTION_PAIDOFF' 'COLLECTION' 'COLLECTION_PAIDOFF'\n",
      " 'PAIDOFF' 'PAIDOFF' 'COLLECTION' 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'PAIDOFF' 'COLLECTION' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF' 'COLLECTION'\n",
      " 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF'\n",
      " 'PAIDOFF' 'COLLECTION' 'COLLECTION' 'COLLECTION' 'PAIDOFF' 'PAIDOFF'\n",
      " 'COLLECTION' 'COLLECTION' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF'\n",
      " 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF'\n",
      " 'COLLECTION' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'COLLECTION'\n",
      " 'PAIDOFF' 'COLLECTION' 'COLLECTION_PAIDOFF' 'COLLECTION' 'COLLECTION'\n",
      " 'COLLECTION_PAIDOFF' 'COLLECTION' 'PAIDOFF' 'PAIDOFF'\n",
      " 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF'\n",
      " 'COLLECTION' 'COLLECTION' 'PAIDOFF' 'COLLECTION' 'PAIDOFF' 'COLLECTION'\n",
      " 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'COLLECTION' 'PAIDOFF'\n",
      " 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'PAIDOFF' 'PAIDOFF' 'COLLECTION' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'COLLECTION' 'PAIDOFF' 'PAIDOFF'\n",
      " 'COLLECTION_PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF'\n",
      " 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF' 'PAIDOFF'\n",
      " 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'PAIDOFF' 'COLLECTION_PAIDOFF']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m original_labels \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_test_label)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(original_labels)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtarget_map\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "target_map = {'COLLECTION':0,\n",
    "  'PAIDOFF':2,\n",
    "  'COLLECTION_PAIDOFF':1}\n",
    "\n",
    "# Reverse the encoding\n",
    "original_labels = label_encoder.inverse_transform(y_test_label)\n",
    "print(original_labels)\n",
    "\n",
    "target_map['COLLECTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 2, 2, 0, 0, 2, 2, 1, 2, 2, 1, 2, 0, 0, 1, 2, 0, 1, 1, 1,\n",
       "       2, 0, 2, 1, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 1, 2, 2, 2, 0, 2, 1, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 0, 1, 2, 2,\n",
       "       1, 2, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 1, 1, 2, 2, 1, 2, 0, 2, 2, 1,\n",
       "       0, 2, 0, 1, 0, 0, 1, 0, 2, 2, 1, 2, 2, 1, 2, 0, 0, 2, 0, 2, 0, 2,\n",
       "       2, 1, 0, 2, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 0, 2, 2,\n",
       "       1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade modelbit --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "    <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #845B99;\">Please upgrade Modelbit</div>\n",
       "    <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">Your Modelbit package appears out of date.</div>\n",
       "    <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "      Please run <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">pip install --upgrade modelbit</span> to upgrade to the latest version.\n",
       "      (Installed: <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">0.42.0</span>.\n",
       "      Latest: <span style=\"margin: 0; padding: 3px; line-height: 1.75; font-size: 13px; vertical-align: baseline; list-style: none; font-family: monospace; background: none; font-weight: 400; background-color: rgba(209, 213, 219, 0.2);\">0.42.1</span>.)\n",
       "    </div>\n",
       "  </div>\n",
       "\n",
       "<div style=\"margin: 0; padding: 5px; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "  <div style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; font-weight: bold; color: #15803d;\">Connect to Modelbit</div>\n",
       "  <div style=\"margin: 0 0 20px 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none;\">\n",
       "    Open <a style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; text-decoration: underline; cursor: pointer;\" href=\"https://us-east-2.aws.modelbit.com/t/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJraW5kIjoiZ2l0IiwidXVpZCI6ImNtMnk3anhocTAwMjgzMW0zNjJ2czhmMzMiLCJpYXQiOjE3MzA0MzM3MTEsImV4cCI6MTczMDQzNDMxMX0.xNbIAux69kq0-DwpWB-hAxKZDFeEdXU4Dh8Rv5wbBTM?source=notebook&amp;branch=main\" target=\"_blank\">modelbit.com/t/eyJhbGciOi...</a> to authenticate this kernel.\n",
       "    <a style=\"margin: 0; padding: 0; line-height: 1.75; font-size: 14px; vertical-align: baseline; list-style: none; font-family: Roboto, Arial, sans-serif; background: none; text-decoration: underline; cursor: pointer;\" href=\"https://doc.modelbit.com/\" target=\"_blank\">Learn more.</a>\n",
       "  </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# install modelbit\n",
    "#!pip install modelbit\n",
    "\n",
    "# run on top of your notebook\n",
    "import modelbit\n",
    "mb = modelbit.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an Inference function\n",
    "The first step is to create a Python function for inference which uses the predict or predict_proba method from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# first define function\n",
    "def predict_loan_default(Principal=0, terms=0,past_due_days=0,\n",
    "                        age=0,education = 'High School' ,Gender = 'male',\n",
    "                        due_date= '9/25/2016',paid_off_time='9/25/2016' ,effective_date = '9/25/2016' ):\n",
    "#def predict_loan_default(Principal:float, terms:float,past_due_days:float,age:float,education:str ,Gender:str,due_date:str ,paid_off_time:str ,effective_date:str)-> float:\n",
    "   \n",
    "  \"\"\"\n",
    "  Predict the probability of loan default using a pre-trained machine learning pipeline.\n",
    " \n",
    "  Args:\n",
    "     \n",
    "      Principal (int): loan principal\n",
    "      terms (int):\n",
    "      past_due_days (int):\t\n",
    "      age (int):\n",
    "      education : str\t\n",
    "      Gender :str\n",
    "      due_date :str\n",
    "      paid_off_time :str\n",
    "      effective_date :str\n",
    "\n",
    "  Returns:\n",
    "      float: Probability of loan default.\n",
    "  \"\"\"\n",
    "  data = pd.DataFrame([[Principal, terms,past_due_days,\n",
    "                        age,education ,Gender,\n",
    "                        due_date,paid_off_time ,effective_date ]],\n",
    "                                             columns = [ 'Principal', 'terms','past_due_days','age','education' ,'Gender','due_date' ,'paid_off_time' ,'effective_date'])\n",
    "  \n",
    "  for col in [ 'Principal', 'terms','past_due_days','age']:\n",
    "    data[col] = data[col].astype(float)\n",
    "  pred_prob = pipeline.predict_proba(data) \n",
    "  \n",
    "\n",
    "  #pred_label = pipeline.predict(pd.DataFrame([[Principal, terms,past_due_days,age,education ,Gender,due_date ,paid_off_time ,effective_date ]],\n",
    "  #                                           columns = [ 'Principal', 'terms','past_due_days','education' ,'Gender','due_date' ,'paid_off_time' ,'effective_date'])) \n",
    "  \n",
    "  #return data\n",
    "  return  dict(zip(['COLLECTION','PAIDOFF','COLLECTION_PAIDOFF'],pred_prob[0]))                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COLLECTION': 0.052470516,\n",
       " 'PAIDOFF': 0.91186875,\n",
       " 'COLLECTION_PAIDOFF': 0.03566072}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_loan_default(800, 15,74,29,'High School or Below','male','9/25/2016','9/12/2016' ,'9/11/2016' )\n",
    "#print(len([800, 15,74,29,'High School or Below','male','9/25/2016','9/12/2016' ,'9/11/2016' ]))\n",
    "#print(len([ 'Principal', 'terms','past_due_days','age','education' ,'Gender','due_date' ,'paid_off_time' ,'effective_date']))\n",
    "#print(len([Principal, terms,past_due_days,age,education ,Gender,due_date ,paid_off_time ,effective_date ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[0.05247052 0.91186875 0.03566072]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Principal       1 non-null      int64  \n",
      " 1   terms           1 non-null      int64  \n",
      " 2   past_due_days   1 non-null      float64\n",
      " 3   age             1 non-null      int64  \n",
      " 4   education       1 non-null      object \n",
      " 5   Gender          1 non-null      object \n",
      " 6   due_date        1 non-null      object \n",
      " 7   paid_off_time   1 non-null      object \n",
      " 8   effective_date  1 non-null      object \n",
      "dtypes: float64(1), int64(3), object(5)\n",
      "memory usage: 204.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "d= pd.DataFrame([[800, 15,74,29,'High School or Below','male','9/25/2016','9/12/2016' ,'9/11/2016' ]],\n",
    "                                             columns = [ 'Principal', 'terms','past_due_days','age','education' ,'Gender','due_date' ,'paid_off_time' ,'effective_date'])\n",
    "\n",
    "d['past_due_days']  = d['past_due_days'].astype(float)\n",
    "\n",
    "print(pipeline.predict_proba(d).argmax() )\n",
    "print(pipeline.predict_proba(d)[0] )\n",
    "\n",
    "#X_test.info()\n",
    "#pipeline.predict_proba()\n",
    "\n",
    "#pipeline.predict_proba(X_test)\n",
    "#print(d)\n",
    "#X_test.head()\n",
    "d.info()\n",
    "\n",
    "#dict(zip(['COLLECTION','PAIDOFF','COLLECTION_PAIDOFF'],pipeline.predict_proba(d)[0]))\n",
    "\n",
    "#predict_loan_default([800, 15,74,29,'High School or Below','male','9/25/2016','9/12/2016' ,'9/11/2016' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'drugA'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install fast_ml --upgrade\n",
    "#predict_loan_default(29, 800, 15,74,'High School or Below','male','9/25/2016','' ,'9/11/2016')\n",
    "#X_test.head()\n",
    "drug_map = {0: \"DrugY\", 3: \"drugC\", 4: \"drugX\", 1: \"drugA\", 2: \"drugB\"}\n",
    "drug_map[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Machine Learning Pipeline on the cloud using Docker Container\n",
    "\n",
    "### Build Web Application\n",
    "This tutorial is not focused on building a Flask application. It is only discussed here for completeness. Now that our machine learning pipeline is ready we need a web application that can connect to our trained pipeline to generate predictions on new data points in real-time. We have created the web application using Flask framework in Python. There are two parts of this application:\n",
    "\n",
    "- Front-end (designed using HTML)\n",
    "- Back-end (developed using Flask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
